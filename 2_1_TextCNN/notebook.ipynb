{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "protecting-fluid",
   "metadata": {},
   "source": [
    "# TextCNN - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-balloon",
   "metadata": {},
   "source": [
    "## 0. import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "departmental-window",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "iraqi-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torchtext.data import Field, TabularDataset, Iterator\n",
    "from konlpy.tag import Mecab\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "suspected-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-german",
   "metadata": {},
   "source": [
    "## 1. Preprocess using torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-wrong",
   "metadata": {},
   "source": [
    "### define Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "characteristic-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_field(max_len: int = 30):\n",
    "    # tokenizer\n",
    "    tokenizer = Mecab()\n",
    "    # document field\n",
    "    doc_field = Field(\n",
    "        sequential=True,\n",
    "        use_vocab=True,\n",
    "        tokenize=tokenizer.morphs,\n",
    "        lower=True,\n",
    "        batch_first=True,\n",
    "        pad_first=True,\n",
    "        fix_length=max_len,\n",
    "    )\n",
    "    # label field\n",
    "    label_field = Field(sequential=False, use_vocab=False, is_target=True)\n",
    "\n",
    "    return doc_field, label_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "occupied-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 30\n",
    "doc_field, label_field = create_field(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-occasions",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-passage",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "premier-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../data/nsmc/ratings_train.txt\"\n",
    "test_path = \"../data/nsmc/ratings_test.txt\"\n",
    "\n",
    "trainset, testset = TabularDataset.splits(\n",
    "    path=\"../data/nsmc/\",\n",
    "    train=\"ratings_train.txt\",\n",
    "    test=\"ratings_test.txt\",\n",
    "    format=\"TSV\",\n",
    "    fields=[(\"id\", None), (\"document\", doc_field), (\"label\", label_field)],\n",
    "    skip_header=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rough-oasis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document': ['아', '더', '빙', '.', '.', '진짜', '짜증', '나', '네요', '목소리'],\n",
       " 'label': '0'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(trainset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-anxiety",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-motorcycle",
   "metadata": {},
   "source": [
    "### build vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "assumed-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_field.build_vocab(trainset, min_freq=10, max_size=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "official-solid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10070"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_field.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "swedish-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_field.vocab.stoi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-windsor",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-purchase",
   "metadata": {},
   "source": [
    "### train, valid split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eligible-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, validset = trainset.split(split_ratio=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "defensive-ultimate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-heading",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-natural",
   "metadata": {},
   "source": [
    "### torchtext dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "proprietary-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train_loader = Iterator(trainset, batch_size=64, shuffle=True, device=device)\n",
    "valid_loader = Iterator(validset, batch_size=64, shuffle=True, device=device)\n",
    "test_loader = Iterator(testset, batch_size=64, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "simple-camera",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(valid_loader))  # 첫번째 미니배치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-delay",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-listing",
   "metadata": {},
   "source": [
    "## 2. TextCNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "instructional-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embed_dim: int,\n",
    "        kernel_sizes: List[int],\n",
    "        kernel_num: int = 100,\n",
    "        class_num: int = 1,\n",
    "    ):\n",
    "        super(TextCNN, self).__init__()\n",
    "\n",
    "        self.kerenel_sizes = kernel_sizes\n",
    "        self.total_kernel_num = kernel_num * len(kernel_sizes)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=1)\n",
    "        self.conv_list = nn.ModuleList(\n",
    "            [nn.Conv2d(1, kernel_num, (ks, embed_dim)) for ks in kernel_sizes]\n",
    "        )\n",
    "        self.linear = nn.Linear(self.total_kernel_num, class_num)\n",
    "\n",
    "    def forward(self, seq):\n",
    "        # embedded_seq: [batch, seq_len, embed_dim]\n",
    "        embedded_seq = self.embedding(seq)\n",
    "        # embedded_seq: [batch, input_ch=1, width(seq_len), embed_dim]\n",
    "        embedded_seq = embedded_seq.unsqueeze(1)\n",
    "\n",
    "        # conv_results: [(batch, output_ch(kernel_num), width)] * len(kernel_sizes)\n",
    "        conv_results = [\n",
    "            F.relu(conv(embedded_seq)).squeeze(3) for conv in self.conv_list\n",
    "        ]\n",
    "\n",
    "        # pooled_results: [(batch, output_ch), ...] * len(kernel_sizes)\n",
    "        pooled_results = [\n",
    "            F.max_pool1d(features, features.shape[2]).squeeze(2)\n",
    "            for features in conv_results\n",
    "        ]\n",
    "\n",
    "        # output: [batch, output_ch * len(kernel_sizes)]\n",
    "        output = torch.cat(pooled_results, dim=1)\n",
    "        output = F.dropout(output, p=0.5)\n",
    "        output = self.linear(output)  # [batch, class_num]\n",
    "        return output.squeeze()\n",
    "\n",
    "    def loss_fn(self, logits, labels):\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        loss = criterion(logits, labels.float())\n",
    "        return loss\n",
    "\n",
    "    def accuracy(self, logits, labels):\n",
    "        logits = torch.round(torch.sigmoid(logits))\n",
    "        corrects = (logits == labels).float().sum()\n",
    "        acc = corrects / labels.numel()\n",
    "        return acc\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        seqs, labels = train_batch\n",
    "        logits = self.forward(seqs)\n",
    "        loss = self.loss_fn(logits, labels)\n",
    "        acc = self.accuracy(logits, labels)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", acc)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        seqs, labels = val_batch\n",
    "        logits = self.forward(seqs)\n",
    "        loss = self.loss_fn(logits, labels)\n",
    "        acc = self.accuracy(logits, labels)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-quarterly",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-missouri",
   "metadata": {},
   "source": [
    "## 3. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fresh-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model init\n",
    "vocab_size = len(doc_field.vocab)\n",
    "embed_dim = 100\n",
    "kernel_sizes = [3, 4, 5]\n",
    "\n",
    "model = TextCNN(vocab_size, embed_dim, kernel_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "exterior-drain",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=5,\n",
    "    val_check_interval=0.5,\n",
    "    # accelerator=\"dp\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "wrapped-office",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | embedding | Embedding  | 1.0 M \n",
      "1 | conv_list | ModuleList | 120 K \n",
      "2 | linear    | Linear     | 301   \n",
      "-----------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4612c720bb944a1c900cd4ef72a70d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-cosmetic",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
